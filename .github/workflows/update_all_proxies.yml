name: Update All Proxy Subscriptions (Matrix)

on:
  schedule:
    # Runs every 3 hours
    - cron: '0 */3 * * *'
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: true

jobs:
  # JOB 1: Prepares the work batches
  prepare-work:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install Dependencies
        run: pip install pyyaml httpx requests

      - name: Run Data Acquisition and Batching
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          python manage_sources.py
          python merge_configs.py
          python prepare_batches.py
          
      - name: Upload Batch Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: work-batches
          path: ci_batches/

  # JOB 2: Runs tests in parallel using a static matrix
  run-tests:
    needs: prepare-work
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        batch_id: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install Dependencies
        run: pip install requests geoip2 pyyaml httpx

      - name: Download GeoIP Database
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: gh release download deps/geoip-latest --repo ${{ github.repository }} --pattern '*.mmdb' --clobber

      - name: Download Batch Artifacts
        uses: actions/download-artifact@v4
        with:
          name: work-batches
          path: ci_batches/
          
      - name: Run Liveness Pipeline on Assigned Batch
        run: |
          BATCH_FILE="ci_batches/batch_${{ matrix.batch_id }}.txt"
          CANDIDATES_FILE="candidates_${{ matrix.batch_id }}.txt"
          # Each worker will create its own small database
          DB_FILE="results_${{ matrix.batch_id }}.db"
          
          python check_liveness.py --output $CANDIDATES_FILE --input $BATCH_FILE
          # Use the simplified exp_country script for liveness-only mode
          python exp_country.py --input $CANDIDATES_FILE --db-file $DB_FILE
          
      - name: Upload Result Artifact
        uses: actions/upload-artifact@v4
        with:
          name: db-result-${{ matrix.batch_id }}
          path: results_${{ matrix.batch_id }}.db

  # JOB 3: Merges all results and publishes
  merge-results:
    runs-on: ubuntu-latest
    needs: run-tests
    if: success()
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install Dependencies
        run: pip install pyyaml jdatetime pytz

      - name: Download All Result Artifacts
        uses: actions/download-artifact@v4
        with:
          path: db_results/
          
      - name: Merge, Generate, and Finalize
        run: |
          python merge_databases.py --input-dir db_results/ --output-db aggregator_data.db
          python create_rotating_sub.py
          python generate_readme.py

      - name: Commit and Push Final Changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action (Matrix)"
          git add .
          
          if ! git diff --staged --quiet; then
            git commit -m "chore: data update via matrix workflow"
            git pull --rebase
            git push
          else
            echo "No changes to commit."
          fi
